# CNN-Activation-Benchmark
A comparative study of five activation functions (ReLU, Sigmoid, Tanh, ELU, and SELU) using custom CNN architectures on the MNIST and CIFAR-10 datasets.
